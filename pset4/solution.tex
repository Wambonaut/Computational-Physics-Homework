% !TEX program = lualatex
% !TEX options = -synctex=1 -interaction=nonstopmode -file-line-error -shell-escape -output-directory=%OUTDIR% "%DOC%"

\documentclass[12pt, a4paper]{article}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[english]{babel}
\usepackage{caption}
\usepackage{float}
\usepackage[left=2cm, top=2cm, right=2cm, bottom=2cm]{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[newfloat, outputdir=out_tex]{minted}
\usepackage{pgf}

\newenvironment{code}{\captionsetup{type=listing}}{}
\newcounter{lstNoteCounter}
\SetupFloatingEnvironment{listing}{name=Source code}


\begin{document}
  
  \centerline{\Huge\scshape Computational physics}
  \vspace*{0.5cm}
  \hrule
  \vspace*{0.5cm}
  \centerline{Jona Ackerschott, Julian Mayr}
  \vspace*{1cm}
  \centerline{\Large\bfseries Problem set 4}
  \vspace*{0.5cm}

  \section*{Problem 1}

  \section*{Problem 2}
  By using the Gauss-Jordan method (with and without pivoting) implemented in {\tt linsolve.py} and, for comparison, LU-decomposition implemented in {\tt scipy.linalg.lu\_factor} and\\ {\tt scipy.linalg.lu\_solve}, on the equation system

  \begin{align}
    \begin{pmatrix} \varepsilon & 1/2 \\ 1/2 & 1/2 \end{pmatrix}
    \begin{pmatrix} x \\ y \end{pmatrix} = 
    \begin{pmatrix} 1/2 \\ 1/4 \end{pmatrix}
    \label{p1_eqsys}
  \end{align}

  \noindent
  one obtains the following results for the solution $(x, y)^T$ with $\varepsilon = 10^{-6}$

  \begin{center}
    \begin{tabular}{l | c | c | c | c}
                                 & $x$        & $y$       & $b_1$       & $b_2$      \\
      \hline
      Gauss-Jordan               & -0.4687500 & 1.0000010 & 0.50000000  & 0.26562548 \\
      \hline
      Gauss-Jordan with pivoting & -0.5000011 & 1.0000011 & 0.50000006  & 0.25000000 \\
      \hline
      LU-decomposition           & -0.5000011 & 1.0000011 & 0.50000006  & 0.25000000
    \end{tabular}
  \captionof{table}{Solutions of (\ref{p1_eqsys}) with $\varepsilon = 10^{-6}$ using the corresponding algorithms. $b_1$ and $b_2$ are the results obtained by backsubstituting the solution into (\ref{p1_eqsys})}.
  \end{center}

  \noindent
  As one can see, the Gauss-Jordan method without pivoting loses some accuracy compared to the LU-decomposition while the Gauss-Jordan method with pivoting does not. By decreasing $\varepsilon$ even further, one cannot observe any loss of accuracy between, or a significant deviation from the exact solution of the latter two methods. However, one gets the following deviation between the Gauss-Jordan method (without pivoting) and the LU-decomposition method, measured by the norm of the difference between the two solutions relative to the LU-decomposition solution.

  \begin{figure}[ht]
    \begin{center}
      \input{figures/fig1_1.pgf}
      \caption{Deviation of the solutions of (\ref{p1_eqsys}) obtained by the Gauss-Jordan method (without pivoting) and LU-decomposition, where $\Delta x$ is the difference of the solution vectors and $x$ is the LU-decomposition solution}
    \end{center}
  \end{figure}

  \newpage\noindent
  So one gets a pretty reasonable solution with a deviation staying at less than $0.5 \%$, if $\varepsilon > 10^{-5}$.
  \section*{Problem 2}
  For a tridiagonal Matrix, the Gauss-Jordan-Algorithm simplifies by only having to consider the previous row of the matrix for each row to get to upper triangle form. For matrix rows $y_n$ and $a_n,b_n,c_n$ as given in the sheet, the iteration step for each line reads:
  \begin{align}
  	y_n=\frac{y_n-a_n*y_{n-1}}{ b_n-c_{n-1}}
  \end{align}
  After Gaussian elimination, the Matrix equation can be solved using backward substitution. For tridiagonal matrices, this also simplifies to
  \begin{align}
  	y_n=y_n-y_{n+1}*y_{n,n+1}
  \end{align}
  since every row only has two elements. The subroutine "solution\_tridiag" in the program implements these two functions and uses them to calculate the solution vector $x_i$. For the given parameters, it yields:
  \begin{align}
  	x=\begin{pmatrix}
  	0.49999999999999994\\0.8999999999999999\\1.2\\1.4000000000000004\\1.5000000000000004\\1.5000000000000004\\1.4000000000000004\\1.2000000000000002\\0.9\\0.5 
  	\end{pmatrix}
  \end{align}
  Testing the equation with this solution and calculating the error gives
  \begin{align}
   \Delta x=\begin{pmatrix}
  -2.7755575615628914e-17\\-1.3877787807814457e-16\\-3.608224830031759e-16\\3.0531133177191805e-16\\8.326672684688674e-17\\8.326672684688674e-17\\8.326672684688674e-17\\-2.7755575615628914e-17\\-1.3877787807814457e-16\\-2.7755575615628914e-17
    \end{pmatrix}
  \end{align}
  Since 64 bit floating point has an accuracy of roughly 16 digits, this lies in floating point error range and is a totally acceptable error.
  \subsubsection*{Source Code}
  \begin{code}
    \inputminted{python}{linsolve.py}
    \captionof{listing}{linsolve.py}
  \end{code}
  \begin{code}
    \inputminted{python}{problem1.py}
    \captionof{listing}{problem1.py}
  \end{code}
	\begin{code}
		\inputminted{python}{problem2.py}
		\captionof{listing}{problem2.py}
	\end{code}

\end{document}
